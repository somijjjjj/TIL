# 데이터 분석이란?

- [1. 데이터분석](#1-데이터분석)

    - [1-1. 문제정의](#1-1-문제-정의)
    - [1-2. 데이터 수집](#1-2-데이터-수집)
    - [1-3. 데이터 분석](#1-3-데이터-분석)
    - [1-4. 검증 및 고찰](#1-4-검증-및-고찰)
    ---
    - [2-1. 데이터 규칙의 종류](#2-1-데이터-규칙의-종류)
    - [2-2. 데이터 분석에 사용되는 변수](#2-2-데이터-분석에-사용되는-변수)
    - [2-3. 데이터 분석 알고리즘](#2-3-데이터-분석-알고리즘)
        - [1. 통계적 알고리즘](#1-통계적-알고리즘)
        - [2. 인공지능 알고리즘](#2-인공지능-알고리즘)
    - [2-4. 알고리즘 특징별 분류](#2-4-알고리즘-특징별-분류)
        - [1. 예측(prediction)](#1-예측prediction)
        - [2. 압축(compression)](#2-압축compression)
        - [3. 분류(classification or clustering)](#3-분류classification-or-clustering)

<br>

> 📖 Reference
-『데이터 분석을 떠받치는 수학』 - 손민규, 위키북스

---



<br>

# 1. 데이터분석
- 수집된 데이터에 숨어 있는 정보를 찾아 가치 있게 만드는 일
- 데이터에서 새로운 의미와 가치를 지닌 정보를 생산하는 일

<br>

데이터 분석을 **누가 어떻게 하느냐에 따라서** 중요한 정보가 발견되거나 아무 의미 없는 정보만 생성되는 등 데이터의 가치가 바뀐다.

분석 알고리즘의 발전과 더불어 무료로 사용할 수 있는 좋은 분석 도구들이 많이 생겼지만,

분석 알고리즘을 정확히 이해하지 못하면 도구를 충분히 활용하지 못하게 된다.  
그렇게 되면 <span style="color:pink">잘못된 결론을 도출하거나 수박 겉핥기 식으로 분석하는 경우</span>가 많아질 수 밖에 없다.

그러므로 정확히 분석하고 분석 결과를 이해하고 활용하기 위해
<span style="color:pink">데이터 분석 프로세스</span>와 <span style="color:pink">데이터 분석 알고리즘에 대한 이해도</span>를 높여야 한다.

<br>


데이터 분석 프로세스는 4단계로 이루어져 있으며  
한 사이클로 끝나지않고 `검증 및 고찰 단계`에서 보완 수정해 다시 `문제 정의`로 이어지는 순환 고리 형식이다.

> 1. 문제 정의  
> 2. 데이터 수집  
> 3. 데이터 분석  
> 4. 검증 및 고찰  


<br>
<br>

# 1-1. 문제 정의
- 목적 : 데이터 분석의 목적은 무엇인가?
- 목표 : 목적을 통해 원하는 목표는 무엇인가?

데이터 분석의 시작단계에서 명확하게 정의한 후 데이터 수집단계로 진행해야 한다.

목적과 목표는 동일한게 아니므로 하나의 목적에 대해서 여러 가지 목표가 있을 수 있다.
> **목적**은 데이터 분석을 통해 최종적으로 얻고싶은 것  
**목표**는 목적을 구체화한 것이나 수단

<br>

##### 예시
| 목적 | 목표 |
|:----------|:----------|
| 내년에 은퇴하는 우리 팀 타격왕 자리를 메울 선수 영입 |비슷한 성향을 가진 타자 조사 |
| 아이스크림 회사의 매출 예측 | 가게의 입지조건으로 일 평균 손님 수 예측 |
| 자동차 회사의 소비자 앙케이트 정보 활용 | 연령별 수익별 잘 팔리는 모델에 대한 분석 |
| 신제품의 공정 개발 기간 단축 | DOE를 통한 공정 파라메터 요인 분석 및 품질 향상 조건 도출 |


<br>

# 1-2. 데이터 수집
- 데이터 정의
- 데이터 수집

1. 생각할 수 있는 모든 관련 데이터에 대해서 모두 정의하고 조사한 것이 가장 중요하다.
✨[피쉬본 다이어그램](https://www.edrawsoft.com/kr/trendy-news/what-is-a-fishbone-diagram.html) 을 이용하면 누락 없이 조사할 수 있다.

2. 조사 결과에서 수집할 수 있는 데이터와 수집할 수 없는 데이터를 구분한다.
*중요한 데이터가 수집할 수 없는 데이터에 포함되어 있다면 **시간이 걸리더라도** 수집할 수 있는 방법을 생각해서 수집한 후 분석을 진행하는 것이 좋다.*


3. 데이터가 정의되었으면, 가지고 있는 데이터의 특성을 파악해야 한다.
데이터의 종료유 따라 이용할 수 있는 데이터 분석 방법이 달라질 수 있으므로 활용하는 데이터에 대해 파악해야 한다.

> ### 데이터의 종류
> **범주형(categorical) 데이터**
> *: 데이터의 값이 숫자가 아닌 여러 개의 범주로 이루어진 데이터*
> - 명목형(nominal)
> 	- 혈액형, 머리 색깔 등
> - 순위형(ordinal) 
> 	- 선호도, 학력 등
>
>  <br>
>
> **수치형(numerical) 데이터**
> - 이산형(discrete) 
> *: 연속적이지 않은 수치 데이터*
> 	- 나이, 방문자 수 등
> - 연속형(continuous)
> *: 연속적인 값을 가지는 수치 데이터*
> 	- 키, 몸무게 등

<br>

수집기간, 수집형태 등 데이터 수집을 어떻게 할 것인가를 결정하기 위해 <span style="color:#EE82EE">실험계획법(design of experiments, DOE)</span>를 활용하면 시간, 돈, 인력이 많이 절약된다.  

<br>

> 실험계획법 ?
> - https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=ksagma&logNo=221079715614  
> - https://ko.wikipedia.org/wiki/%EC%8B%A4%ED%97%98%EA%B3%84%ED%9A%8D%EB%B2%95  
> - https://wooono.tistory.com/136


<br>
<br>

# 1-3. 데이터 분석
- 데이터 전처리
- 기초 통계 분석
- 모델 구축 및 평가

<br>

1. 데이터 전처리 과정
결측치, 이상치, 중복값 등을 처리해 품질이 좋은 데이터로 통합하는 과정.
데이터 분석 과정에서 대단히 <span style="color:pink">중요하므로 시간들여서 신중하게</span> 진행해야 한다.

> ##### 결측값 처리 
> ###### 결측값이 있는 데이터를 삭제하거나 채우는 것. 결측값을 채우는 방법은 해당 변수의 일정 기간 동안의 평균, 중앙값, 최빈값 등 대푯값을 채우는 방법 등이 있음.
  
<br>

> ##### 이상치 처리
> ###### 비정상적인 이상한 값, 데이터 분포나 통계분석을 통해 이상치라고 판단이 되면 제거하거나 평활화(smoothing)를 하여 중간값으로 대체하는 방법 등이 있음.
  
<br>

> ##### 중복값 처리
> ###### 여러 개의 데이터 중에서 하나만 남기고 삭제함

<br>
<br>

2. 기초 통계 분석 과정
데이터의 평균, 표준편차와 같은 대푯값과 데이터 간의 상관계수 등을 계산해 각 데이터의 특성을 파악하는 과정.
의미가 없는 데이터는 제거하면서 일차적으로 데이터 분석에 필요한 변수들을 선택한다.

전체 데이터 분석 과정(100)에서 <span style="color:pink">전처리 과정, 기초 통계 분석 과정이 70을 차지할 정도로 중요</span>하다.
**데이터의 특성을 파악하고, 특성에 맞는 기초 통계값을 추출**하는데 노력을 기울일수록 좋은 결과를 얻을 수 있다!

<br>

3. 모델 구축 및 평가 과정
본격적인 데이터 분석이 이루어지는 과정.
- 통계적 알고리즘
	- 분산분석, 회귀분석, 주성분 분석, 요인분석, 판별분석 등
    
- 머신러닝 or 데이터 마이닝 알고리즘

*모델이란 각 알고리즘이 데이터 분석을 진행하면서 생성하는 로직이나 수식*

일반적으로 7:3비율을 사용하여 훈련 데이터(training data)와 테스트 데이터(test data)로 나눈다.
훈련 데이터를 이용해 여러 가지 알고리즘을 사용하여 모델을 만든 후 테스트 데이터를 이용해 모델의 성능을 평가한다.
이 평과를 바탕으로 다시 데이터 분석을 하며 최적의 알고리즘과 모델을 선택한다.


<br>

# 1-4. 검증 및 고찰

데이터 분석 결과는 크게 두 가지 형태로 만들어 진다.

1. 분석 보고서(analysis report)
- 데이터를 분석해 얻은 새로운 정보와 앞으로의 방향 등
- 일반적으로 여론조사, 시장조사 데이터 등을 분석한 경우에 이런 결과를 얻어 마케팅 등에 활용된다.

2. 회귀식과 같은 모델
- 주로 기업 등의 생산 데이터나 품질 데이터를 분석했을 때 얻을 수 있는 결과
- 데이터 분석의 결과를 실무에 적용해 생산성이나 품질 향상을 기대할 수 있다.

검증 결과를 고찰하며 개선이 필요하다면 다시 문제를 정의하고 데이터 분석을 시작한다.

<br>
<br>


---

<br>
<br>



# 2-1 데이터 규칙의 종류

#### 1. 화이트박스 알고리즘
결정 트리(decision tree), 트리 구조를 그래프로 그려 보면 알고리즘이 어떤 규칙을 만들어 냈는지 이해할 수 있다.

#### 2. 블랙박스 알고리즘
딥러닝(deep learning)의 기본구조인 신경망(neural network), 신경망의 학습결과는 가중치 벡터(weight vector) 형태로 나타나지만, 사람이 해석하기에는 무리가 있다.

<br>



# 2-2 데이터 분석에 사용되는 변수


#### 1. 종속변수
결과를 나타내는 변수로서, 일반적으로 Y로 표시.
  - 변수 개수에 따른 분석 종류
      - 1개 : 일변량 분석
      - 2개 : 이변량 분석
      - 3개 이상 : 다변량 분석
   
#### 2. 독립변수
종속변수의 원인에 해당하는 변수로서, 일반적으로 X로 표시
  - 변수 개수에 따른 분석 종류
      - 1개 : 단변수 분석 or 일변량 분석 or 단변량 분석
      - 2개 : 다변수 분석 or 다변량 분석

<br>



# 2-3 데이터 분석 알고리즘 

### 1. 통계적 알고리즘
수집된 데이터에 대해서 어떤 규칙을 가지고 있는지 분석,
발견된 규칙을 알고리즘과 같이 만들어서 활용

- 분산분석
- 회귀분석
- 주성분분석
- 요인분석
- 판별분석

> **회귀분석, 주성분분석**은 인공지능의 한 가지인 **데이터 마이닝 분야**에서도 사용된다.
*요즘에는 통계적 알고리즘, 인공지능 알고리즘의 경계가 애매모호해지고 있다.*

### 2. 인공지능 알고리즘
대량의 데이터로부터 데이터에 대한 규칙을 알고리즘이 찾아내게 만드는 방법

- 결정 트리
- 신경망
- 유전 알고리즘(genetic algorithm)
- 서포트 벡터 머신(support vector machine)

<br>


# 2-4 알고리즘 특징별 분류

### 1. 예측(prediction)
종속변수와 독립변수 사이의 인과관계를 이용하여 모델을 만들어서 종속변수의 값을 예측한다.
   - 선형 회귀분석(linear regression)
   - 서포트 벡터 머신(support vector machine)
   
 > 회귀분석은 수익 예측, 생산량 예측, 종속변수에 영향을 미치는 변수를 찾기 위한 가장 기본적인 알고리즘.
 회귀분석을 이용하여 1차 분석을 진행한 후
 좀 더 고도화된 알고리즘인 PCR, PLS, 서포트 벡터 회귀(support vector regression) 등을 사용하게 된다.

<br>

### 2. 압축(compression)
데이터의 차원을 축소하기 위해 사용되는 알고리즘
독립변수들 간의 관계를 분석하여 정보를 압축한다.
   - 주성분분석(principal component analysis)
   - 요인분석(factor analysis)
      
 > 주성분분석은 많은 데이터를 압축할 때 쓰는 알고리즘.
 데이터를 다른 방향으로 바라볼 수 있게 변환하여 데이터를 분석할 수 있는 도구로도 많이 사용된다.
 *여론조사, 앙게이트 결과 종합 분석 등*

 <br>

   
### 3. 분류(classification or clustering)

  #### 3-1. 분류(classification)
  : 종속변수를 기준으로 독립변수의 특징을 학습시켜 분류를 하는 알고리즘.

  이런 방법은 정답(종속변수)을 알려주는 교사학습(supervised learning, 지도학습)이다.
     - 결정트리(decision tree), 
     - 마할라노비스-다구치-시스템(Mahalanobis-Taguchi system)
     
 > 마할라노비스-다구치-시스템은 정상/비정상을 분류하는 최적의 알고리즘.  
      비정상의 종류가 너무 많아 모든 비정상의 상태를 정의 할 수 없을 때,  
       정상 상태만을 정의해서 정상/비정상을 분류하는 대표적인 시스템.
     
  <br>

  #### 3-2. 군집화(clustering)
  : 독립변수의 속성을 파악해 비슷한 속성을 가진 데이터끼리 군집화하는 알고리즘.
  
  이런 방법은 정답(종속변수)이 없고, 비교사 학습(unsupervised learning, '비지도 학습' 또는 '자율 학습')이라 한다.
     - 자기 조직화 지도(self-organizing map)

